def __init__(self, env, hidden_size=512, policy_lr=3e-4, gamma=0.99, 
             clip_epsilon=0.2, batch_size=2048, ent_coef=0.01, gae_lambda=0.95):
    # Increase network capacity
    self.rnn = nn.LSTM(input_size, hidden_size, num_layers=2, dropout=0.1).to(self.device)
    self.fc = nn.Sequential(
        nn.Linear(hidden_size, 256),
        nn.ReLU(),
        nn.Linear(256, env.action_space.n)
    ).to(self.device)
    # Add learning rate scheduler
    self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=10000) 
def train(self, env, epsilon=0.1):
    # In the training loop:
    if random.random() < epsilon:
        # Weighted random exploration
